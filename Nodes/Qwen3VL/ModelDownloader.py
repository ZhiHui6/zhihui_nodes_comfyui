import os
import time
import folder_paths
from pathlib import Path
import threading
from typing import Optional, Dict, Any

class ModelDownloader:
    
    def __init__(self):
        self.download_status = {}
        self.download_thread = None
        
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "model": (
                    [
                        "Qwen3-VL-4B-Instruct",
                        "Qwen3-VL-4B-Thinking", 
                        "Qwen3-VL-8B-Instruct",
                        "Qwen3-VL-8B-Thinking",
                        "Huihui-Qwen3-VL-8B-Instruct-abliterated",
                        
                    ],
                    {"default": "Qwen3-VL-8B-Instruct"},
                ),
                "platform": (
                    ["huggingface", "hf-mirror", "modelscope"],
                    {"default": "hf-mirror"},
                ),
                "force_redownload": ("BOOLEAN", {"default": False}),
            },
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("info",)
    FUNCTION = "download_model"
    CATEGORY = "Zhi.AI/Qwen3VL"

    def get_platform_config(self, platform: str, model: str = None) -> Dict[str, Any]:
        configs = {
            "huggingface": {
                "repo_prefix": "qwen",
                "endpoint": None,
                "use_hf_hub": True,
            },
            "hf-mirror": {
                "repo_prefix": "qwen", 
                "endpoint": "https://hf-mirror.com",
                "use_hf_hub": True,
            },
            "modelscope": {
                "repo_prefix": "qwen",
                "endpoint": None,
                "use_hf_hub": False,
            }
        }
        
        config = configs.get(platform, configs["huggingface"])
        
        if platform == "modelscope" and model and "abliterated" in model:
            config = config.copy()
            config["repo_prefix"] = "ayumix5"
            
        return config

    def get_model_save_path(self, model: str) -> str:
        models_dir = os.path.join(folder_paths.models_dir, "prompt_generator")
        return os.path.join(models_dir, model)

    def check_model_exists(self, model_path: str) -> bool:
        if not os.path.exists(model_path):
            return False
        
        required_files = ["config.json"]
        for file in required_files:
            if not os.path.exists(os.path.join(model_path, file)):
                return False
        
        return True

    def download_from_huggingface(self, repo_id: str, local_dir: str, 
            endpoint: Optional[str] = None) -> bool:
        try:
            from huggingface_hub import snapshot_download
            import os
            import requests
            
            if endpoint:
                os.environ["HF_ENDPOINT"] = endpoint
            
            print(f"å¼€å§‹ä» {'HF-Mirror' if endpoint else 'HuggingFace'} ä¸‹è½½æ¨¡å‹: {repo_id}")
            print(f"ä¿å­˜è·¯å¾„: {local_dir}")
            
            snapshot_download(
                repo_id=repo_id,
                local_dir=local_dir,
                local_dir_use_symlinks=False,
                resume_download=True,
            )
            
            if endpoint and "HF_ENDPOINT" in os.environ:
                del os.environ["HF_ENDPOINT"]
                
            return True
            
        except requests.exceptions.Timeout as e:
            if endpoint and "HF_ENDPOINT" in os.environ:
                del os.environ["HF_ENDPOINT"]
            platform_name = 'HF-Mirror' if endpoint else 'HuggingFace'
            print(f"ğŸš« {platform_name} è¿æ¥è¶…æ—¶: {str(e)}")
            return False
            
        except requests.exceptions.ConnectionError as e:
            if endpoint and "HF_ENDPOINT" in os.environ:
                del os.environ["HF_ENDPOINT"]
            platform_name = 'HF-Mirror' if endpoint else 'HuggingFace'
            print(f"ğŸš« æ— æ³•è¿æ¥åˆ° {platform_name} æœåŠ¡å™¨: {str(e)}")
            return False
            
        except Exception as e:
            print(f"HuggingFaceä¸‹è½½å¤±è´¥: {str(e)}")
            if endpoint and "HF_ENDPOINT" in os.environ:
                del os.environ["HF_ENDPOINT"]
            return False

    def download_from_modelscope(self, repo_id: str, local_dir: str) -> bool:
        try:
            from modelscope import snapshot_download as ms_snapshot_download
            import requests
            
            print(f"å¼€å§‹ä» ModelScope ä¸‹è½½æ¨¡å‹: {repo_id}")
            print(f"ä¿å­˜è·¯å¾„: {local_dir}")
            
            ms_snapshot_download(
                model_id=repo_id,
                local_dir=local_dir,
                revision="master"
            )
            
            return True
            
        except ImportError:
            print("ğŸš« ModelScope åº“æœªå®‰è£…ï¼Œè¯·å®‰è£…: pip install modelscope")
            return False
            
        except requests.exceptions.Timeout as e:
            print(f"ğŸš« ModelScope è¿æ¥è¶…æ—¶: {str(e)}")
            return False
            
        except requests.exceptions.ConnectionError as e:
            print(f"ğŸš« æ— æ³•è¿æ¥åˆ° ModelScope æœåŠ¡å™¨: {str(e)}")
            return False
            
        except Exception as e:
            print(f"ModelScopeä¸‹è½½å¤±è´¥: {str(e)}")
            return False

    def download_model_async(self, model: str, platform: str, model_path: str, 
                            force_redownload: bool):
        try:
            config = self.get_platform_config(platform, model)
            
            repo_id = f"{config['repo_prefix']}/{model}"
            
            self.download_status[model] = {
                "status": "downloading",
                "progress": 0,
                "message": f"æ­£åœ¨ä» {platform} ä¸‹è½½æ¨¡å‹..."
            }
            
            if force_redownload and os.path.exists(model_path):
                import shutil
                shutil.rmtree(model_path)
                print(f"å·²åˆ é™¤ç°æœ‰æ¨¡å‹ç›®å½•: {model_path}")
            
            os.makedirs(model_path, exist_ok=True)
            
            success = False
            if config["use_hf_hub"]:
                success = self.download_from_huggingface(
                    repo_id, model_path, config["endpoint"]
                )
            else:
                success = self.download_from_modelscope(repo_id, model_path)
            
            if success:
                self.download_status[model] = {
                    "status": "completed",
                    "progress": 100,
                    "message": f"æ¨¡å‹ä¸‹è½½å®Œæˆ: {model_path}"
                }
                print(f"âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸ: {model}")
            else:
                self.download_status[model] = {
                    "status": "failed", 
                    "progress": 0,
                    "message": f"æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–å°è¯•å…¶ä»–å¹³å°"
                }
                print(f"âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥: {model}")
                
        except Exception as e:
            self.download_status[model] = {
                "status": "failed",
                "progress": 0, 
                "message": f"ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
            }
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {str(e)}")

    def download_model(self, model: str, platform: str, force_redownload: bool = False):
        
        model_path = self.get_model_save_path(model)
        
        if force_redownload and os.path.exists(model_path):
            import shutil
            shutil.rmtree(model_path)
            print(f"å·²åˆ é™¤ç°æœ‰æ¨¡å‹ç›®å½•: {model_path}")
        
        if not force_redownload and self.check_model_exists(model_path):
            info_msg = f"âœ… æ¨¡å‹å·²å­˜åœ¨ï¼Œæ— éœ€é‡æ–°ä¸‹è½½\nğŸ“ æ¨¡å‹è·¯å¾„: {model_path}\nğŸ’¡ å¦‚éœ€é‡æ–°ä¸‹è½½ï¼Œè¯·å‹¾é€‰'å¼ºåˆ¶é‡æ–°ä¸‹è½½'é€‰é¡¹"
            return (info_msg,)
        
        if (model in self.download_status and 
            self.download_status[model]["status"] == "downloading"):
            current_status = self.download_status[model]
            info_msg = f"â³ {current_status['message']}\nğŸ“ ç›®æ ‡è·¯å¾„: {model_path}"
            return (info_msg,)
        
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½æ¨¡å‹: {model} (å¹³å°: {platform})")
        
        self.download_thread = threading.Thread(
            target=self.download_model_async,
            args=(model, platform, model_path, force_redownload)
        )
        self.download_thread.daemon = True
        self.download_thread.start()
        
        time.sleep(1)
        
        if model in self.download_status:
            current_status = self.download_status[model]
            info_msg = f"â³ {current_status['message']}\nğŸ“ ç›®æ ‡è·¯å¾„: {model_path}"
        else:
            info_msg = f"â³ æ­£åœ¨åˆå§‹åŒ–ä¸‹è½½: {model}\nğŸ“ ç›®æ ‡è·¯å¾„: {model_path}"
        
        return (info_msg,)